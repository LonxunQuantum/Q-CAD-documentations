PWMat Machine Learning Force Field
========================================

Overview
----------

PWmat Machine Learning Force Field (PWmatMLFF) is an open source software under GNU license. It aims at generating force fields with accuracy comparable to Ab Initio Molecular Dynamics (AIMD). It is compatible with AIMD data with either **PWmat** or **VASP** format. You can access the code from https://github.com/LonxunQuantum/MLFF, or http://www.pwmat.com/pwmat-resource/module-download/file/MLFF.zip. 

You can also access our online AIMD data archive via https://www.jianguoyun.com/p/DUWoiP4Ql-_OChiEk8IEIAA

This package contains 8 types of features with translation, rotation, and permutation invariance, which are

        1. 2-body(2b)
        2. 3-body(3b) 
        3. 2-body Gaussian(2bgauss)
        4. 3-body Cosine(3bcos) 
        5. Multiple Tensor Potential(MTP)
        6. Spectral Neighbor Analysis Potential(SNAP)
        7. DP-Chebyshev(dp1)        
        8. DP-Gaussian(dp2) 

and 4 engines for training and prediction, which are 

        1. Linear Model
        2. Graphic Neural Netowrk (GNN)
        3. Deep Neural Netowrk with Kalman Filter optimizer(KFNN)
        4. DP-torch Network with Kalman Filter optimizer(KFDP) 


A complete MLFF workflow contains 3 major steps. **First**, use eitehr PWmat or VASP to run AIMD calculation to generate training data (features and direvatives of features, .etc), and perform post-processing of the data. **Second**, run training to obtain the force field, and monitor the **validation** result to see if overfitting occurs; **Finally**, use the obtained force field to make inference. 

There are two kinds of inference: **evaluation** and **prediction**. **Evaluation** is a more rigorous assessment of the force field.  In practice, ene first prepares a MOVEMENT file generated by Ab Initio calculation, use the obtained force field to calculate energy and force, and compare them against the Ab Initio results. Error given by this test is usually larger than the error given in the validation.

In comparison, **prediction** solves real challenges. Like Ab Initio MD calculations, it starts with a initial configuration, and simulates the ensuing process based on the force field and the conditions specified. Both **LAMMPS** and **PWmat** can be used.  

Installation
-------------

On Mcloud
+++++++++++

Mcloud is equipped with a ready-to-use MLFF environment. Use the following commands to load MLFF environment

::

    source /share/app/anaconda3/etc/profile.d/conda.sh
    module load intel/2020
    module load cuda/11.3
    module load MLFF/2022.05.23
    conda activate mlff

On your own workstation 
+++++++++++++++++++++++


Install the conda environment first. To install, use the following command. You may choose a new version of Anaconda. 

::

    wget https://repo.anaconda.com/archive/Anaconda3-2020.07-Linux-x86_64.sh

Then, create a new environment for this module. We recommend using Python 3.8.  

::
    
    conda create -n mlff python=3.8

After mlff has been created, re-enter the current environment.
        
:: 
    
    conda deactivate
    conda activate mlff

After this, install the following packages. 

::

    conda install pandas
    conda install matplotlib
    conda install scikit-learn-intelex
    conda install numba         
    conda install tensorboard
    conda install -c conda-forge/label/cf202003 dpdata
    conda install git 
    conda install --channel conda-forge pymatgen

**If you wish to use the GNN model**, also clone and install the following package, in accordance with the steps given within 

::
    
    git clone https://github.com/mir-group/pair_nequip.git

Next, check if your CUDA version is **11.3**. If not, update to or install CUDA 11.3. Install pytorch with the following command 

..
    Next, you should identify the architecture of your Nvidia GPU and install a compatible pytorch version. We take RTX 3080Ti as an example. It is fabricated in Ampere architecture, and requires CUDA 11.1 or later. **Also**, the one-click installation via conda only supports 4 CUDA versions, which are CUDA 10.2, CUDA 11.1 CUDA 11.3 and CUDA 11.5. Thus, CUDA 11.1, CUDA 11.3 and CUDA 11.5 are reasonable choices for RTX 3080Ti. We can therefore use CUDA 11.3 for PyTorch. 

    If you are wokring on a cluster, you should contact the system adsministrator to load the appropriate CUDA version.

    If you are working on your own workstation, you might need to install CUDA manually: Visit https://developer.nvidia.com/cuda-toolkit-archive to obtain the correct version, and install locally. After installation, you should set the following environment variables correctly, so that the latest CUDA can be detected:
    
    ::  

        export PATH=/my/cuda/path/bin:$PATH
        export LD_LIBRARY_PATH=/my/cuda/path/lib64:$LD_LIBRARY_PATH
        export CUDADIR=/my/cuda/path

    In default, CUDA will be installed in /usr/local. 
    
::

    conda install pytorch cudatoolkit=11.3 -c pytorch 

Also, make sure your g++ supports **C++ 14** standard. Use "g++ --version" to check, and version above 7.0 should be fine. Intel compiler is also required. 

..
    The way to load a speific CUDA version differs across platforms. If you are working on a cluster, it is common to use **module load** command to load specific CUDA library. If you are working on your own workstation, unless a specific CUDA version is pre-installed, you should install it on your own. Refer to Nvidia official website for more details. 

    You can check the following article to determine which CUDA to use on your GPU device.  

    ::

        https://arnon.dk/matching-sm-architectures-arch-and-gencode-for-various-nvidia-cards/

    Having configured CUDA correctly, enter **src/op** and run the following commands to compile acceleration modules. Notice that the compilation must take place on host that has available GPU. If you are working on a cluster, you can use the the following to start a interactive job for compilation. 

    ::

        srun -p mygpupartition --gres=gpu:1 --pty bash


..
    **You should make sure that your g++ compiler supports C++ 14 standard!** G++ version greater than 7 will do.  

    .. Warning::
        For stability consideration, do not attempt to upgrade GCC/G++ by yourself. Contact system administrator for help. 


    Also, you should modify the path in setup.py. It should be the bin directory in your CUDA path. To obtain the CUDA path, use 

    ::

        echo $CUDADIR

    and the path in setup.py file should therefore be:

    ::

        what/echo/CUDADIR/tells/you/bin

    To compile, use the following command.

    ::

        python3 setup.py install  

    MLFF switches to use the above modules when GPU is available. However, this is a good option only for KFDP engine. For KFNN, training on GPU appears less efficient than on CPU. Certainly, we will bring modifications in future releases to better utlize the power of GPU in KFNN. We will eleborate on how to choose the computing device in following sections. 

    Now, enter the src directory and compile source codes. Intel 2020 module must be loaded. 

Enter **/src** and start building with

:: 

    sh build.sh
    


If the building is successful, modify the following environment variables

::

    vim ~/.bashrc 
    export PATH=absolute/path/to/PWmatMLFF/src/bin:$PATH
    export PYTHONPATH=absolute/path/to/PWmatMLFF/src/:$PYTHONPATH
    source ~/.bashrc 


LAMMPS
++++++

Linear Model, KFNN, and KFDP
^^^^^^^^^^^^^^^^^^^^^^^^^^^^

MLFF provides an interface for LAMMPS. You should compile LAMMPS from the source code in order to use it. Intel Fortran and C++ compilers are required. 

First, obtain LAMMPS's source code and unzip it. Create a directory called **PWMATMLFF** in LAMMPS's **src** directory, and copy all content under **src/md** into **PWMATMLFF**. 

::

    cd path/to/lammps/src/PWMATMLFF
    cp path/to/mlff/src/md . -r 

In src/PWMATMLFF, *remove* line 118 in the **makefile**:

::

    \cp main_MD.x ../../bin/

which is a stand-alone PWMat MD program. 

Run make to compile

::

    make 

Now, go back to LAMMPS's **src/** and run 


::

    make yes-pwmatmlff


This step tells LAMMPS to include our interface during compiling. After this, copy **src/PWMATMLFF/Makefile.mpi** into **src/MAKE**

::

    cp /PWMATMLFF/Makefile.mpi /MAKE

and make

::

    make mpi

This will generate an executable called **lmp_mpi** in **/src**. You might need to add an environment variable to make this executable visible elsewhere. 

::

    export PATH=/path/to/your/lammps/src/:$PATH


GNN
^^^^

**If you wish to use GNN for in LAMMPS**, see the page below for guidance. 

::

    https://github.com/mir-group/pair_nequip


Quickstart
-------------

To start training, you should first prepare the AIMD data with either VASP or PWmat. You can use the ultily module **outcar2movement** to convert VASP's OUTCAR output to MOVEMENT format. In the directory that contains the OUTCAR file, run: 

::
    
    outcar2movement

.. Warning::
    When using PWmat for AIMD calculation, add the following flags in **etot.input**:

    ::

        energy_decomp = T
        e_error = 1.0e-6
        rho_error = 1.0e-4

    This enables PWmat to perform atomic energy decomposition with high precision, which is crucial in data preparation. You will find that besides Velocity, Force, and Position blocks, a block called **Atomic Energy** will show up in the MOVEMENT file, which includes the decomposed atomic energy of each atom. 


Code examples for each model are now presented, with all parameters set to be default. A complete introduction on parameters will be given in next section.

Linear Model 
++++++++++++

Training
^^^^^^^^

All MOVEMENT files must be stored in the directory **/PWdata**. If more than one MOVEMENT files are used for training, create multiple directories within **/PWdata**, with each containing **exactly ONE** MOVEMENT file. You can use **data/MOVEMENT** for a quick test. 

::
    
    # import module from PWmatMLFF 
    from PWmatMLFF.linear_regressor import linear_regressor 

    if __name__ == "__main__":

        """
            atom types to be used
            MUST BE SPECIFIED
        """
        atom_type = [29,8]

        """
            feature to be used
            MUST BE SPECIFIED
        """
        feature_type = [1,2]
        
        """
            create a class instance
            MUST BE DONE
        """
        linReg = linear_regressor(atom_type = atom_type, feature_type = feature_type)
        
        """
            generate training data 
            ONLY NEED TO BE DONE ONCE
        """"
        linReg.generate_data() 
        
        """
            start training 
            the results are automatically saved in the current directory 
        """
        linReg.train() 

Paste the code above in python script (**main.py**, for example). Run the following command to train 

::

    python main.py 

Evaluation
^^^^^^^^^^

Before evaluation, create a directory **/MD**,  and put in it another MOVEMENT file obtained from AIMD. **Note that for such a MOVEMENT, energy decomposition is necessary**.

::
    
    # import module from PWmatMLFF 
    from PWmatMLFF.linear_regressor import linear_regressor 

    if __name__ == "__main__":
        
        """
            atom types to be used
            MUST BE SPECIFIED
        """
        atom_type = [29,8]

        """
            feature to be used
            MUST BE SPECIFIED
        """
        feature_type = [1,2]
        
        """
            create a class instance
            MUST BE DONE
        """
        linReg = linear_regressor(atom_type = atom_type, feature_type = feature_type)
        
        """
            perform evaulation and plot 
        """ 
        linReg.evaluate() 
        linReg.plot_evaluation() 


Prediction
^^^^^^^^^^

The code below runs **PWmat-style** MD calculation with the force field just obtained. For MD calculation with LAMMPS, see the section "**LAMMPS MD calculation**". You must prepare an initial configuration in order to proceed. A **md_detail** array is also required, which specifies 1)simulation method, 2) steps, 3) time lentgh of step, 4) initial temperature, and 5) final temperature. Please refer to PWmat manual for more details. 

::
    
    # import module from PWmatMLFF 
    from PWmatMLFF.linear_regressor import linear_regressor 

    if __name__ == "__main__":
        
        """
            atom types to be used
            MUST BE SPECIFIED
        """
        atom_type = [29,8]

        """
            feature to be used
            MUST BE SPECIFIED
        """
        feature_type = [1,2]
        
        """
            create a class instance
            MUST BE DONE
        """
        linReg = linear_regressor(atom_type = atom_type, feature_type = feature_type)
        
        """
            PWmat-style md_detail array
            MUST BE SPECIFIED 
        """   
        md_detail = [1,1000,1,500,500]

        """
            run MD
        """
        linReg.linReg.run_md(md_details = md_detail, follow = False)

This process generates all information in the current directory as in PWmat MD calculation. 


Deep Neural Network
++++++++++++++++++++

Training
^^^^^^^^

All MOVEMENT files must be stored in the directory **/PWdata**. If more than one MOVEMENT files are used for training, create multiple directories within **/PWdata**, with each containing **exactly ONE** MOVEMENT file. You can use **data/MOVEMENT** for a quick test. Notice that for Deep Neural Network, training with **global Kalman Filter** optimizer on **cpu** is recommended. 

::

    #import the regressor module
    from PWmatMLFF.nn_network import nn_network 

    if __name__ == '__main__':

        # atom type to be used. MUST BE SPECIFIED 
        atom_type = [29,8]

        # feature to be used. MUST BE SPECIFIED 
        feature_type = [1,2]

        # create an instance. MUST BE DONE. 
        kfnn_trainer = nn_network(
                                    atom_type = atom_type,   
                                    feature_type = feature_type, 
                                    kalman_type = "global",      # using global Kalman filter
                                    device = "cpu",              # run training on cpu 
                                    recover = False,             # recover previous training
                                    session_dir = "record"       # directory that contains 
                                 )
        
        # generate data from MOVEMENT files
        # ONLY NEED TO BE DONE ONCE
        kfnn_trainer.generate_data()

        # transform data
        kfnn_trainer.load_data()

        # initialize the network   
        kfnn_trainer.set_model() 

        # initialize the optimizer and related scheduler
        kfnn_trainer.set_optimizer()

        # set epoch number for training
        kfnn_trainer.set_epoch_num(20)

        # start training 
        kfnn_trainer.train() 
        

Paste the code above in python script (**main.py**, for example). Run the following command to train 

::

    python main.py 


During training, you can monitor the progress by checking the logs in the **session_dir** you specified:  

**epoch_loss.dat**: RMSE_Etot, RMSE_Ei, RMSE_F of training set in each epoch. 

**epoch_loss_valid.dat**: RMSE_Etot, RMSE_Ei, RMSE_F of valid set in each epoch.  

Evaluation
^^^^^^^^^^

Before evaluation, create a directory **/MD**,  and put in it another MOVEMENT file obtained from AIMD. **Note that for such a MOVEMENT, energy decomposition is necessary**.

::

    #import the regressor module
    from PWmatMLFF.nn_network import nn_network 

    if __name__ == '__main__':

        # atom type to be used. MUST BE SPECIFIED 
        atom_type = [29,8]

        # feature to be used. MUST BE SPECIFIED 
        feature_type = [1,2]

        # create an instance. MUST BE DONE. 
        kfnn_trainer = nn_network(   
                                    atom_type = atom_type,   
                                    feature_type = feature_type, 
                                    kalman_type = "global",      # using global Kalman filter
                                    device = "cpu",              # run training on cpu 
                                    recover = False,             # recover previous training
                                    session_dir = "record"       # directory that contains the log & saved models 
                                 )

        # extract network parameters for inference module. MUST-HAVE, ONLY ONCE
        kfnn_trainer.extract_model_para()

        # run evaluation
        kfnn_trainer.evaluate() 

        # plot the evaluation result
        kfnn_trainer.plot_evaluation() 

Prediction
^^^^^^^^^^

The code below runs **PWmat-style** MD calculation with the force field just obtained. For MD calculation with LAMMPS, see the section "**LAMMPS MD calculation**". You must prepare an initial configuration in order to proceed. A **md_detail** array is also required, which specifies 1)simulation method, 2) steps, 3) time lentgh of step, 4) initial temperature, and 5) final temperature. Please refer to PWmat manual for more details. 

::

    #import the regressor module
    from PWmatMLFF.nn_network import nn_network 

    if __name__ == '__main__':

        # atom type to be used. MUST BE SPECIFIED 
        atom_type = [29,8]

        # feature to be used. MUST BE SPECIFIED 
        feature_type = [1,2]

        # create an instance. MUST BE DONE. 
        kfnn_trainer = nn_network(   
                                    atom_type = atom_type,   
                                    feature_type = feature_type, 
                                    kalman_type = "global",      # using global Kalman filter
                                    device = "cpu",              # run training on cpu 
                                    recover = False,             # recover previous training
                                    session_dir = "record"       # directory that contains the log & saved models 
                                 )

        # extract network parameters for inference module. MUST-HAVE. ONLY ONCE 
        kfnn_trainer.extract_model_para()   

        # md_detail array
        md_detail = [1,1000,1,300,300]

        # run MD  
        kfnn_trainer.run_md(md_details = md_detail, follow = False)

This process generates all information in the current directory as in PWmat MD calculation. 

DP-Torch Network
++++++++++++++++

Training
^^^^^^^^

All MOVEMENT files must be stored in the directory **/PWdata**. If more than one MOVEMENT files are used for training, create multiple directories within **/PWdata**, with each containing **exactly ONE** MOVEMENT file. You can use **data/MOVEMENT** for a quick test. Notice that the layerwise Kalman filter oprimizer is used by default. **It is recommended to run training on GPU**. 

::

    from PWmatMLFF.dp_network import dp_network

    if __name__ == "__main__":

        # atom type to be used. MUST BE SPECIFIED 
        atom_type = [29,8]

        # create an instance. MUST BE DONE. 
        dp_trainer = dp_network(device = "cuda",atom_type = atom_type, session_dir = "kfdp_record")
        
        # generating trianing data. ONLY NEED TO BE DONE ONCE
        dp_trainer.generate_data() 
        
        # load data into memeory 
        dp_trainer.load_data()  
        
        # initialize network 
        dp_trainer.set_model()
        
        # set optimzer 
        dp_trainer.set_optimizer()
        
        # set epoch num
        dp_trainer.set_epoch_num(10)
        
        #start training 
        dp_trainer.train()  

Paste the code above in python script (**main.py**, for example). Run the following command to train 

::

    python main.py 


During training, you can monitor the progress by checking the logs in the **session_dir** you specified:  

**epoch_loss.dat**: RMSE_Etot, RMSE_Ei, RMSE_F of training set in each epoch. 

**epoch_loss_valid.dat**: RMSE_Etot, RMSE_Ei, RMSE_F of valid set in each epoch.  

Evaluation
^^^^^^^^^^
Before evaluation, create a directory **/MD**,  and put in it another MOVEMENT file obtained from AIMD. **Note that for such a MOVEMENT, energy decomposition is necessary**.

::

    from PWmatMLFF.dp_network import dp_network

    if __name__ == "__main__":

        # atom type to be used. MUST BE SPECIFIED 
        atom_type = [29,8]

        # create an instance. MUST BE DONE. 
        dp_trainer = dp_network(device = "cuda",atom_type = atom_type, session_dir = "kfdp_record")
        
        # extract network parameters for inference. MUST BE DONE
        dp_trainer.extract_model_para()

        # run evaluation 
        dp_trainer.evaluate() 

        # (optinal) plot RMSE graph
        dp_trainer.plot_evaluation() 

Prediction
^^^^^^^^^^
The code below runs **PWmat-style** MD calculation with the force field just obtained. For MD calculation with LAMMPS, see the section "**LAMMPS MD calculation**". You must prepare an initial configuration in order to proceed. A **md_detail** array is also required, which specifies 1)simulation method, 2) steps, 3) time lentgh of step, 4) initial temperature, and 5) final temperature. Please refer to PWmat manual for more details. 

::

    from PWmatMLFF.dp_network import dp_network

    if __name__ == "__main__":

        # atom type to be used. MUST BE SPECIFIED 
        atom_type = [29,8]

        # create an instance. MUST BE DONE. 
        dp_trainer = dp_network(device = "cuda",atom_type = atom_type, session_dir = "kfdp_record")
        
        # extract network parameters for inference. MUST BE DONE
        dp_trainer.extract_model_para()

        # md_detail array. MUST-HAVE

        # run MD 
        dp_trainer.run_md(md_details = md_detail, num_thread = 4, follow = False)

This process generates all information in the current directory as in PWmat MD calculation. 

Graphic Neural Network
++++++++++++++++++++++

Training
^^^^^^^^

All MOVEMENT files must be stored in the directory **/PWdata**. If more than one MOVEMENT files are used for training, create multiple directories within **/PWdata**, with each containing **exactly ONE** MOVEMENT file. You can use **data/MOVEMENT** for a quick test. **Notice that you have to manually specify the size of training set and validation set**. 

::

    from PWmatMLFF.gnn_network import gnn_network

        if __name__ == "__main__":
            
            # atomic symbols. MUST-HAVE 
            atom_type = ["Cu","O"]
        
            # creating class instance. MUST-HAVE
            gnn_trainer = gnn_network(  device = "cuda", # choose the device for training 
                                        chemical_symbols = atom_type
                                        )
            
            gnn_trainer.set_epoch_num(20)

            # set number of image in training and validation
            # Notice that nequip picks up training and validation set randomly. 
            gnn_trainer.set_num_train_img(400)
            gnn_trainer.set_num_valid_img(400)
            
            # create directory for current session 
            gnn_trainer.set_session_dir("record")

            # specify task name
            gnn_trainer.set_task_name("20220902-test")
            
            # generate data 
            # ONLY NEED TO BE DONE ONCE! 
            gnn_trainer.generate_data() 

            # lanuch training 
            gnn_trainer.train() 
            

Evaluation
^^^^^^^^^^

You must specify the directory used for training when running evaluation. Images that are used in neither training nor validation are to be evaluated. 

::

    from PWmatMLFF.gnn_network import gnn_network

        if __name__ == "__main__":
            
            # atomic symbols. MUST-HAVE 
            atom_type = ["Cu","O"]
        
            # creating class instance. MUST-HAVE. 
            gnn_trainer = gnn_network(  device = "cuda", # choose the device for training 
                                        chemical_symbols = atom_type
                                        ) 
            
            # lanuch evaluation 
            # Notice that train_dir MUST BE SPECIFIED. 
            gnn_trainer.evaluate(device = "cpu",train_dir = "record/20220902-test")


Prediction
^^^^^^^^^^

GNN force field can only be used in LAMMPS. First, you should deploy the model. 

::

    from PWmatMLFF.gnn_network import gnn_network

        if __name__ == "__main__":
            
            # atomic symbols. MUST-HAVE 
            atom_type = ["Cu","O"]
        
            # creating class instance. MUST-HAVE. 
            gnn_trainer = gnn_network(  device = "cuda", # choose the device for training 
                                        chemical_symbols = atom_type
                                        ) 
            
            # lanuch evaluation 
            # Notice that train_dir MUST BE SPECIFIED. 
            gnn_trainer.evaluate(device = "cpu",train_dir = "record/20220902-test")

You also need to compile LAMMPS manually to support the GNN pair style. See section **""LAMMPS MD calculation""**. 


LAMMPS MD calculation
+++++++++++++++++++++

Linear Model,KFNN, and KFDP
^^^^^^^^^^^^^^^^^^^^^^^^^^^

To use LAMMPS for MD calculation, you should add these lines in LAMMPS's input file:

::

    
    pair_style pwmatmlff
    pair_coeff  * * 1 5 29

The first line specify pair style. In the second line, the first 2 stars are place holders which need not to be changed. "1" stands for the **method index** you want to use, 5 means calculating neighbors in every 5 steps. 29 is the first type of atom (in this case, Cu) in the system. Notice that for system with more than 1 type of element, all elements should listed. For example, if the system is CuO, the second line should be: 

::

    pair_coeff  * * 1 5 8 29

.. Note::

    Method indices for each model are:

    **Linear Model**: 1 

    **KFNN**: 3
    
    **KFDP**: 5

You should also make sure that Intel MKL library is loaded. On MCloud, use the following command: 

::  

    module load mkl

Remember that in **NN and DP-torch**, you still need to extract the network parameters before launching LAMMPS

::
    
    my_trainer.extract_model_para() 

Now, run LAMMPS with 

::

    mpirun -n myNodeNum /path/to/lammps/src/lmp_mpi -in lammps.in

GNN
^^^^

To use LAMMPS with **GNN** model, see 

::

    https://github.com/mir-group/nequip
    https://github.com/mir-group/pair_nequip

for more details. 

..
    Generate AIMD training data 
    ----------------------------

    **PWmat**

    You should first run AIMD on the system of interst to obtain training data, which is simply the MOVEMENT file generated by the MD calculation. As a common practice, we run several MD simulations under different conditions(such as temperature), each of which goes for a several thousands MD steps. The idea behind is to have enough atomic configurations to cover all the situations you might encounter in later force field-based preidictions.  

    PWmat's unique energy decomposition functionality can be ultilized during generating training data. To use it, set **energy_decomp = T** in etot.input. You might also need to adjust **energy_decomp_special** in accordance with you situation. Please be sure to refer to PWmat's manual for details involving MD calculations. 

    An etot.input example for MD calcualtion is given below. 

    :: 

        16  1
        JOB = MD
        IN.PSP1 = Cu.SG15.PBE.UPF
        IN.ATOM = atom.config
        MD_DETAIL = 3 2000 0.8 300 300
        E_Cut = 60 
        precision = double
        
        mp_n123 = 1 1 1 0 0 0 2
        xcfunctional = GGA

        energy_decomp = T       #this flag must be true
        E_error = 1.0e-6
        Rho_error = 1.0e-4

    **VASP**

    You can use the ultily module **outcar2movement** to convert VASP's OUTCAR output to MOVEMENT format. In the directory that contains the OUTCAR file, run: 

    ::
        
        outcar2movement


    You can find the resultant MOVEMENT file in the same directory. 

    .. Note::
        VASP does not decompose the total enery into atomic energy. However, in MLFF's data preprocessing, the total energy in the training data is constructed by summing up all the atomic energy. In MOVEMENT file converted from OUTCAR, you will notice that all atomic energy is simply the total energy divided by the number of atom. Thus, DO NOT use atomic energy for training when your training data is generated by VASP, since atomic energy here only serves as a means to obtain the value of the total energy. This also is why all 4 models use the total energy and the force as default training input.  

    ..
        **Principles for generating trianing data**

        As the first principle, training data set should well represent the 3N-dimensional phase space, where N is the number of atoms. That is, data should include the system’s spatial configurations as many as possible. The reason is self-evident under the framework of energy decomposition. In our example, the training data is usually made up of images from more several MD results with varying condtitions. However, these images are sampled from the raw data, otherwise data size can be overwhelming. We now use some naïve rules to pick up images from the raw data. We may introduce more complex sampling method in the future. 

    Generate training data
    -----------------------

    You should first create a working directory for your system.  For instance, our example data is a Cu bulk system, and you can create a directory called "Cu_bulk" for it 

    ::  
        
        mkdir Cu_bulk 

    Enter this directory, and create a director called "PWdata" for MOVEMENT files. 

    .. image:: pictures/PWdata.png 

    In Cu_bulk, create a directory callled **PWdata**. In PWdata, **create a single directory for each MOVEMENT file you wish to train**, and move all the MOVEMENT files in their corresponding directory. Notice that it is ok for different MOVEMENT to have different atom number. Name of the directory does not matter here. For example, 

    .. image:: pictures/data123.png 

    Notice that in each directory, the name of MOVEMENT file must be "MOVEMENT". Other names are not allowed. 

    It is very important to put multiple MOVEMENT files in seperate directories: that being said, do not concatenate multiple MOVEMENT files into one. This is because in **seper.py** which will be used in KFNN and KFDP, a simple 80%-20% cut is used to form the training set and the validation set. Without doing so, you will probably end up with having a case that is not trained at all and only used as validation data! 

    Go back to Cu_bulk, and create a python script called **parameters.py**. Like etot.input in PWmat, it is the master script that contains the relevant parameters. **In MLFF workflow, this is the only file user needs to modify**.     

    Now, the feature generation may starts. Set the following parameters in **parameters.py**: 

    **atomType**: the atomic numbers. In the example case, system consists of only Cu, thus atomType should be [29]. If the system contains more than one element, all atomic numbers should be specified. For instance, atomType should be [8,29] for CuO. **Importantly**, the order of each type of atom must match that in the MOVEMENT file! 

    **use_Ftype**: features fed into the training process. Usually, combinations such as [1,2],[3,4],[5],[6],[7],[8] are used, but you are free to explore other combinations. In the given example, we use [1,2]. Note that feature 6 could be slow. 

    **isCalcFeat**: set to be True. Notice that this step will generate feature output files that can be reused by other training processes. They are stored in directory fread_dfeat. 

    Besides, you should pay attention to the following parameter: 

    ..
        **Rc_M**: the cutoff radius of feature generation, in Angstrom. Since all of our 8 features are "local", which assumes that atomic properties such as energy are determined by near neighbors, this parameter controls how many neighbors are taken into account when generating features. Its default value is 6, but we recommand you trying different values for different system.   

    **maxNeighborNum**: size of neighbor buffer, with default value 100. However, for some systems it is not enough to accommodate all the neighbors, and the feature generation fails. The following warning will pop up: 

    ::
        
         Error! maxNeighborNum too small

    ..
        When this happens, you should assign **maxNeighborNum** with a larger number. For each type of feature, the required neighbor buffer size is also printed on the screen. For example, for feature 2, the following screen output indicates that **maxNeighborNum** should be at least 135. 

        ::
            
            gen_3b_feature.x
            max,nfeat0m = 135

    After parameters.py are all set, run mlff.py in the current directory to obtain the features. 

    ::
        
        mlff.py

    Having generated the feature data, you can now feed them into various training models. **isCalcFeat** should be turned off now. 

Parameter details
-----------------

This section introduces the user-definable parameters in all models. There are 2 types of parameters: **gloabl** and **local**.


**Global parameters**: Most (but not all) gloabl parameters can either be passed in when creating the trainer class instance, or be altered via memebr function **.set_<name_of_parameter>()**. Example: for parameter called **mypara**, it can be passed in when the trainer class is created, 

::

    my_trainer = trainer(
                            ...
                            mypara = val,
                            ...
                        )

or via a member function ( for example, **set_mypara()**):

::

    ...
    my_trainer.set_mypara(val)
    ...

Unless otherwise noted, all global parameters listed below can be altered in **both ways**. 

**Local parameters**: these parameters are only effective with memeber functions such as train(), evaluate(), .etc. 

Linear Model 
++++++++++++

Global parameters
^^^^^^^^^^^^^^^^^

**max_neigh_num**: size of neighbor buffer, with default value **100**. However, for some systems it is not enough to accommodate all the neighbors, and the feature generation fails. The following warning will pop up: 

::
    
    Error! maxNeighborNum too small

In this case increase the value. 

Usage: **trainer.set_neigh_num(val)** or pass in at the instantiation 

****

**etot_weight**: weight of total energy in fitting. Default value is **0.5**. 

Usage: **trainer.set_etot_weight(val)** or pass in at the instantiation 

*****

**force_weight**: weight of force in fitting. Default value is **0.5**. 

Usage: **trainer.set_force_weight(val)** or pass in at the instantiation 

*****

**ei_weight**: weight of atomic energy in fitting. Default value is **0.0**. 

Usage: **trainer.set_ei_weight(val)** or pass in at the instantiation 

Local parameters: Training
^^^^^^^^

None. 

Local parameters: Evaluation
^^^^^^^^^^

The complete list of parameters in evaluation is 

::

    evaluate(num_thread=1)

**num_thread**: number of threads for evaluation. Default is 1. 


Local parameters: Prediction
^^^^^^^^^^
The complete list of parameters in prediction: 

::

    run_md(init_config = "atom.config", md_details = None, num_thread = 1, follow = False)

**init_config**: inital configuration file for MD. Default is **atom.config**

*****

**md_details**: md_detail array. Must be passed in by user. 

*****

**num_thread**: number of threads for prediction. Default is 1. 

*****

**follow**: if continue previous MD run. Default is False.

Deep Neural Network 
+++++++++++++++++++


Global parameters
^^^^^^^^^^^^^^^^^

**max_neigh_num**: size of neighbor buffer, with default value **100**. However, for some systems it is not enough to accommodate all the neighbors, and the feature generation fails. The following warning will pop up: 

::
    
    Error! maxNeighborNum too small

In this case increase the value. 

Usage: **my_trainer.set_neigh_num(val)** or pass in at the instantiation 

****

**is_trainForce**: if force is used in training. Default is True

Usage: **my_trainer.set_train_force(val)** or pass in at the instantiation  

*******

**is_trainEi**: if atomic energy is used in training. Default is False

Usage: **my_trainer.set_train_Ei(val)** or pass in at the instantiation  

*****

**is_trainEgroup**: if group energy is used in training. Default is False

Usage: **my_trainer.set_train_Egroup(val)** or pass in at the instantiation  

*****

**is_trainEtot**: if total energy is used in training. Default is True

Usage: **my_trainer.set_train_Etot(val)** or pass in at the instantiation  

*****

**kf_prefac_Etot**: KF update prefactor for total energy. Default is 1.0. Can be understood as the "learning rate" for KF. 

Usage: **my_trainer.set_kf_prefac_Etot(val)**

*****

**kf_prefac_Ei**: KF update prefactor for atomic energy. Default is 1.0

Usage: **my_trainer.set_kf_prefac_Ei(val)**

****

**kf_prefac_F**: KF update prefactor for force. Default is 1.0

Usage: **my_trainer.set_kf_prefac_F(val)**

****

**kf_prefac_Egroup**: KF update prefactor for group energy. Default is 1.0

Usage: **my_trainer.set_kf_prefac_Egroup(val)**

****

**session_dir**: name of directory that saves the training log and models. Default is **record**

Usage: **my_trainer.set_session_dir(val)** or pass in at the instantiation  

****

**device**: device for traning. Default is cpu 

Usage: pass in at the instantiation  

****

**recover**: if recover previous training. Default is False. 

Usage: pass in at the instantiation  

****

**n_epoch**: number of epoch. Default is 25

Usage: **my_trainer.set_epoch_num(val)** or pass in at the instantiation  

****

Local parameters:Training
^^^^^^^^^^^^^^^^^

Complete list of parameters in member function **set_model()**: 

::
    
    set_model(start_epoch = 1, model_name = None)

**start_epcoh**: start epoch number. No need to vary. 

**model_name**: the model name to be load when **recover=True**. Default value is **latest.pt**, which is the latest model. 


Local parameters: Evaluation
^^^^^^^^^^^^^^^^^

Complete list of parameters in member function **evaluate()**: 

::

    evaluate(num_thread=1)

**num_thread**: number of threads for evaluation. Default value is 1.

********

Complete list of parameters in member function **extract_model_para()**: 

::

    extract_model_para(model_name = "latest.pt") 

**model_name**: the name of model to be extracted. Default values is  **latest.pt**

Local parameters: Prediction
^^^^^^^^^^^^^^^^^

The complete list of parameters in prediction: 

::

    run_md(init_config = "atom.config", md_details = None, num_thread = 1, follow = False)

**init_config**: inital configuration file for MD. Default is **atom.config**

*****

**md_details**: md_detail array. Must be passed in by user. 

*****

**num_thread**: number of threads for prediction. Default is 1. 

*****

**follow**: if continue previous MD run. Default is False.

DP-torch Network 
+++++++++++++++++++

Global parameters
^^^^^^^^^^^^^^^^^

**max_neigh_num**: size of neighbor buffer, with default value **100**. However, for some systems it is not enough to accommodate all the neighbors, and the feature generation fails. The following warning will pop up: 

::
    
    Error! maxNeighborNum too small

In this case increase the value. 

Usage: **my_trainer.set_neigh_num(val)** or pass in at the instantiation 

****

**kf_prefac_Etot**: KF update prefactor for total energy. Default is 1.0. Can be understood as the "learning rate" for KF. 

Usage: **my_trainer.set_kf_prefac_Etot(val)**

*****

**kf_prefac_F**: KF update prefactor for force. Default is 1.0

Usage: **my_trainer.set_kf_prefac_F(val)**

*******

**session_dir**: name of directory that saves the training log and models. Default is **record**

Usage: **my_trainer.set_session_dir(val)** or pass in at the instantiation  

****

**device**: device for traning. Default is cpu

Usage: pass in at the instantiation 

****

**recover**: if recover previous training. Default is False. 

Usage: pass in at the instantiation  

****

**n_epoch**: number of epoch. Default is 25

Usage: **my_trainer.set_epoch_num(val)** or pass in at the instantiation  

****

**batch_size**: batch size. Default is 1. 

Usage: **my_trainer.set_batch_size(val)** or pass in at the instantiation  

****

**select_num**: number of selected atoms for force update in KF. Default is 24. 

Usage: **my_trainer.set_select_num(val)** or pass in at the instantiation  

*****

**group_size**: number of groups the selected atoms will be divided into. Default is 6

Usage: **my_trainer.set_group_size(val)** or pass in at the instantiation  


******

**block_size**: block size in layerwise KF. Default is 5120

Usage: **my_trainer.set_block_size(val)** or pass in at the instantiation  

**********

**embedding_net_config**: configuration of the embedding network, i.e. number of nodes in each layer. Default is [25, 25, 25] with KF, and [25, 50, 100] without KF 

Usage: **my_trainer.set_embedding_net_config(val)** or pass in at the instantiation  

********

**fitting_net_config**: configuration of the fitting network, i.e. number of nodes in each layer. Default is [50, 50, 50, 1] with KF, and [240, 240, 240, 1] without KF 

Usage: **my_trainer.set_fitting_net_config(val)** or pass in at the instantiation  

***********

**Rmin**: low cut-offin DP's smoothing function. Default is 3.0

Usage: **my_trainer.set_Rmin(val)** or pass in at the instantiation  

**********

**Rmax**: high cut-off in DP's smoothing function. Default is 5.4

Usage: **my_trainer.set_Rmax(val)** or pass in at the instantiation  

Local parameters:Training
^^^^^^^^^^^^^^

Complete list of parameters in member function **set_model()**: 

::
    
    set_model(start_epoch = 1, model_name = None)

**start_epcoh**: start epoch number. No need to vary. 

**model_name**: the model name to be load when **recover=True**. Default value is **latest.pt**, which is the latest model. 

Local parameters: Evaluation
^^^^^^^^^^

Complete list of parameters in member function **evaluate()**: 

::

    evaluate(num_thread=1)

**num_thread**: number of threads for evaluation. Default value is 1.

Local parameters: Prediction
^^^^^^^^^^

The complete list of parameters in prediction: 

::

    run_md(init_config = "atom.config", md_details = None, num_thread = 1, follow = False)

**init_config**: inital configuration file for MD. Default is **atom.config**

*****

**md_details**: md_detail array. Must be passed in by user. 

*****

**num_thread**: number of threads for prediction. Default is 1. 

*****

**follow**: if continue previous MD run. Default is False.

Graphic Neural Network 
+++++++++++++++++++

Global parameters
^^^^^^^^^^^^^^^^^

**device**: device to train. Default is **"cuda"**.

Usage: **my_trainer.set_device()** or pass in at the instantiation 

****

**session_dir**: directory that contains training tasks. Default is **"record"**

Usage: **my_trainer.set_session_dir()** or pass in at the instantiation 

****

**task_name**: directory under *session_dir* that stores the inforrmation of each task. Default is **"gnn"**

Usage: **my_trainer.set_task_name()** or pass in at the instantiation 

****

**epoch_num**: number of epoch. Default is 25. 

Usage: **my_trainer.set_epoch_num()** or pass in at the instantiation 

****

**num_train_img**: number of images for training. **YOU MUST SPECIFY THIS BASED ON YOU DATASET**

Usage: **my_trainer.set_num_train_img()** or pass in at the instantiation 

****

**num_valid_img**: number of images for validation. **YOU MUST SPECIFY THIS BASED ON YOU DATASET**

Usage: **my_trainer.set_num_valid_img()** or pass in at the instantiation 

****

**num_train_batch_size**: number of images for training. Default is 5, and **1 to 5 are reasonable choices**.

Usage: **my_trainer.set_train_batch_size()** or pass in at the instantiation 

****

**num_valid_batch_size**: number of images for training. Default is 10. 

Usage: **my_trainer.set_valid_batch_size()** or pass in at the instantiation 

****

**learning_rate**: learning rate. Default is 0.005. 

Usage: **my_trainer.set_learning_rate()** or pass in at the instantiation 

****

**r_max**: cutoff radius in Angstrom. Default is 4.0 

Usage: **my_trainer.set_r_max()** or pass in at the instantiation 

****

**num_layers**: number of interaction blocks. Default is 4 

Usage: **my_trainer.set_num_layers()** or pass in at the instantiation 

****

**l_max**: the maximum irrep order (rotation order) for the network's features. Default is 1, which is good enough for most cases. 

Usage: **my_trainer.set_l_max()** or pass in at the instantiation 

****

**num_features**: number of features. Default is 32, which is good enough for most cases. 

Usage: **my_trainer.set_num_features()** or pass in at the instantiation 

****

**num_basis**: number of features. Default is 32, which is good enough for most cases. 

Usage: **my_trainer.set_num_basis()** or pass in at the instantiation 

****

**num_basis**: number of basis functions used in the radial basis. Default is 8, which is good enough for most cases. 

Usage: **my_trainer.set_num_basis()** or pass in at the instantiation 

****

**PolynomialCutoff_p**: p-exponent used in polynomial cutoff function, smaller p corresponds to stronger decay with distance. Default is 6.

Usage: **my_trainer.set_PolynomialCutoff_p()** or pass in at the instantiation 

****

**invariant_layers**: number of radial layers. Default is 2. 1 to 3 are reasonable. 

Usage: **my_trainer.set_invariant_layers()** or pass in at the instantiation 


Local parameters:Training
^^^^^^^^^^

Complete list of parameters in member function **generate_data()**: 

::

    generate_data(xyz_output = "./PWdata/training_data.xyz") 

**xyz_output**: name of .xyz file after coversion. Default values is  **./PWdata/training_data.xyz**

********

Complete list of parameters in member function **train()**: 

::

    train(train_data = r"./PWdata/training_data.xyz")

**train_data**: .xyz to be used in training. Default values is  **./PWdata/training_data.xyz**

Local parameters:Evaluation
^^^^^^^^^^

Complete list of parameters in member function **evaluate()**:

::

    evaluate(
                    train_dir = None,
                    model = None,   
                    batch_size = 50, 
                    device = None, 
                    use_deterministic_algorithms = False
            )


**train_dir**: path to the data set to be evaluated. Images that are **NOT** used in training and validation will be used

**model**: the model to be evaluated. **MUST BE A DELOPYED MODEL**

**batch_size**: batch size.

**device**: device for evaluation task 

**use_deterministic_algorithms**: if a deterministic method is used in evaluation. Notice that if CUDA is used, algorithms are non-deterministic, and forcing it using deterministic method may induce error. Set **device = cpu** instead. 

*******

Complete list of parameters in member function **deploy()**:

::

    deploy( 
                model = None, 
                train_dir = None, 
                out_file = None
            )

**model**: model to be deployed. Default is **best_model.pth** in **train_dir**

**train_dir**: directory that contains the model to be deployed 

**out_file**: name of the output file

